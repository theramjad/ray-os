Include
Mention Aparajita's plan manager: https://github.com/aparaji

## Mindset

1. **The only limit is your imagination** — you can get it to edit videos, reconnect to Starbucks Wi-Fi automatically, make your own software to exploring your DNA, use dating app API endpoints to get a girlfriend. If you want more detail, I cover this in my Claude Code Masterclass.
2. **Update your mental model of where the models are** — they're capable of more than you think. Don't assume "the model can't do this." Just try it and you'll often be surprised.
3. **Let the model discover context itself** — don't front-load 20 files into the conversation. The task might be simpler than you think, or you might give it the wrong files and waste context window on irrelevant info.
4. **Be aware of "code bias"** — agents are biased toward existing code patterns. When stuck in loops, the agent can't think outside the current codebase's configuration. Try asking a different model for a fresh approach, then feed that back. This applies to other bias, sometimes I just run Claude Code in a brand new folder from scratch to get it to implement something and copy that over into the old project.

## Setup & Environment

5. **Use `--dangerously-skip-permissions` with sandboxing to block internet access** — get fully autonomous speed while scoping Claude's reach to only what's safe. The hooks act as the guardrail that makes the permission skip safe.
6. **Use hooks for guardrails, linting, and blocking destructive actions** — hooks run before or after every tool call and act as deterministic guardrails around the non-deterministic agent. Pre-tool hooks prevent prompt injection — even if Claude gets injected via malicious file or web content, it can't send emails or run destructive commands. Post-tool hooks auto-run linting, formatting, or type checking after every edit so Claude fixes issues in the same turn instead of leaving them for you. You can also block specific destructive patterns like `rm -rf` or database drops — set these up in `/permissions` so even `--dangerously-skip-permissions` won't bypass them.
7. **Use Ghostty as your terminal** — GPU-accelerated, native splits, tab renaming, command palette (`Cmd+Shift+P`), and bell features that integrate perfectly with Claude Code hooks.
8. **Ring the terminal bell when Claude needs your input** — add a global Notification hook in `~/.claude/settings.json` with matcher `permission_prompt|idle_prompt` that runs `tput bel`. Pair with Ghostty's `bell-features = title,attention` so background tabs get a bell indicator that clears when you focus them. When you're juggling multiple Claude instances across tabs, the bell tells you exactly which tab needs attention — you just switch to the one with the indicator, handle it, and move on. It turns Ghostty into a notification system for your parallel Claude sessions.
9. **Split panes to run multiple Claude sessions side-by-side** — in Ghostty: `Cmd+D` splits right, `Cmd+Shift+D` splits down, `Cmd+Option+Arrows` moves focus. Run one Claude per pane for parallel workstreams.
10. **Use Obsidian as your notes/docs tool** — your vault is just markdown files on disk, so Claude can read, write, and link them directly. Backlinks and graph view let you spot patterns across notes.
11. **Use a voice-to-text tool for prompting** — talk instead of type. It's faster for explaining what you want, especially for longer or more nuanced prompts. Tools like HyperWhisper work well.
12. **Use `/add-dir` to work across two projects at once** — migrating logic between apps? Have Claude look at how payments are set up in app A, then copy the relevant logic into app B in a way that fits. Struggling with a feature? Download a working open-source GitHub repo that implements something similar, `/add-dir` it, and tell Claude to compare their implementation with yours and find discrepancies. You can allow it just for the session or permanently remember that directory.

## Context Engineering

13. **Use hierarchical CLAUDE.md files** — there are three levels: enterprise-wide rules at `~/.claude/CLAUDE.md` (coding standards, compliance), project rules at `./CLAUDE.md` (architecture, conventions), and personal preferences at `.claude/CLAUDE.local.md` (gitignored — your own style like "I'm a beginner with TypeScript, explain changes clearly"). They load in order, higher levels first. Within each file, rules are read top to bottom in priority order — put your most important rules at the top ("never do X", "always do Y") with clear snippets and examples. The project CLAUDE.md can live in the root or in `.claude/CLAUDE.md` — both work the same. Share it via Git so the whole team gets the same instructions. When you commit it, keep the bar high — strip out anything that's just your local file paths or personal preferences, because every teammate's context window will load this file.
14. **Keep root CLAUDE.md short** — put platform-specific context in subdirectory CLAUDE.md files. If you have a monorepo with a Next.js website and a macOS app, each subfolder gets its own CLAUDE.md with only relevant instructions. Claude Code reads memories recursively — when it's editing files in the macOS folder, it loads that subfolder's CLAUDE.md automatically.
15. **Use `@file` references to split large context** — when your CLAUDE.md grows too long, extract sections into separate files and reference them with `@claude-memories/i18n.md`. For example, your i18n formatting rules, your database schema conventions, or your design system tokens can each live in their own file. Claude loads them only when it encounters the `@` reference.
16. **As your project grows, add more CLAUDE.md files** — agent confusion increases with codebase size. When Claude starts making weird decisions in a specific area of your codebase, that's a signal you need a subdirectory CLAUDE.md there. These files activate only when Claude reads or edits files in that folder, keeping context focused and reducing noise.
17. **Close the feedback loop** — feed real-world results back to the agent. If Claude generated YouTube titles, give it the A/B test data a day later. It writes learnings into a memory doc and gets better every round. I've been doing this for two months with my YouTube titles — Claude runs the A/B test via the Chrome extension, then one day later automatically checks which title won, updates its memory document with what worked, and generates better titles next round. Most people skip this step — they generate ideas, never tell the agent how those ideas performed, and the agent makes the same mistakes forever. Give your agent access to the same dashboards you have.
18. **Use Memory Mode to save key decisions** — when Claude discovers something important mid-session (an architectural decision, a naming convention, a gotcha about your codebase), tell it to save it to memory so future sessions benefit. This is especially useful for decisions that aren't obvious from the code alone — like "we chose Supabase over Firebase because of X" or "the download modal uses a specific animation timing."
19. **Ask Claude to update your CLAUDE.md — never edit it manually** — when Claude makes a mistake or you notice it doing something wrong, fix it manually and then tell Claude "update the rules so we never do this again." It'll add the right rule to the right CLAUDE.md file. Think of it like lint rules — every mistake becomes a permanent fix. Over time, your CLAUDE.md evolves into a living style guide shaped by real sessions, not hypothetical rules you wrote upfront.

## Prompting

20. **Give goals, not instructions** — "add IP restriction for AI agents" beats "read file X, edit line 42, add an if statement." The model has seen millions of implementations; let it pick the best approach. Vercel found this too — they removed a bunch of over-engineered custom tools and replaced them with just ExecuteCommand and ExecuteSQL. Their success rate went from 80% to 100%, 3.5x faster, fewer tokens.
21. **Use the agent's own terminology in follow-up prompts** — if Claude calls it a "CDN download URL" vs "direct download URL," use those exact terms. It helps it find the right code faster and be more precise. If Claude mentions "disposable domain checking," reference that phrase back — it'll know exactly what part of the codebase you mean. If you find yourself pushing Claude hard to get it to do something, your terminology is probably wrong.
22. **Use screenshots to show Claude what you want** — it's multimodal. Screenshot a UI bug, a design reference, or a competitor's feature and drop it into the conversation. You can also screenshot mockups or designs and use them as lightweight PRDs — much faster than writing out exactly what you want.
23. **Tell Claude to ask you clarifying questions first** — for complex features, say "ask me questions before starting." In plan mode, this triggers the Interactive Questions tool which shows up to four multiple-choice or free-text questions at a time. Claude will ask about grid sizes, navigation methods, edge cases — stuff you'd forget to specify. Answer them, submit, and the plan will be way more comprehensive.
24. **Use `/rewind` when Claude goes in the wrong direction** — instead of trying to talk it back on course, rewind to before the bad turn and re-prompt with better guidance. This is cleaner than arguing with stale context, because the bad decisions are removed from the conversation entirely instead of lingering and biasing future outputs.

## Planning

25. **Start in plan mode for non-trivial features** — switch to plan mode with `Shift+Tab`, describe what you want (use voice-to-text for speed), let Claude explore the codebase, then review the plan before any code gets written. I describe the feature, it explores the analytics API patterns, database schema, and existing code, then comes back with a plan after about five minutes.
26. **Use a spec developer skill for comprehensive plans** — a custom slash command that asks you detailed clarifying questions about edge cases, then produces an 800+ line implementation plan with file references. I answered 20-30 questions from the spec developer — things like "should there be region groups for the country picker?" and "how should IP data be shown to creators?" — stuff I would have missed. The resulting plan has references to every file that needs changing.
27. **Reject the initial plan and run spec developer** — the first plan often misses edge cases. Reject it, invoke spec developer, answer its targeted questions, and get a much more thorough plan. The spec developer asks much better questions after Claude has already done an initial exploration of the codebase.
28. **Have explore subagents check the codebase before spec developer asks questions** — tell it to "first explore the codebase with 4-5 explore subagents based on the plan before asking me questions." When the spec developer's questions are grounded in actual code (not just the plan), you get questions about real edge cases in your specific codebase rather than generic ones.
29. **After implementation, spawn 5 explore subagents to verify the plan** — assign each to check a different aspect of the plan and ensure full coverage. Report back with anything missing from the codebase that wasn't implemented. If both Claude Code and Codex confirm the plan was fully implemented, you can be pretty confident it was done right.
30. **Plan in one session, execute in another** — spend a whole session exploring, testing, and refining a plan. Write it to a file. Start a fresh session at 10-15% context and tag the plan file. The implementation will be faster and more focused — I've seen it go from 58% context usage down to 21% in the new session, and the code quality is better because there's no poisonous early context from failed explorations or dead-end ideas.
31. **Re-enter plan mode for the next stage of the plan** — after Claude finishes implementing one section, switch back into plan mode before tackling the next section. This forces it to re-read the plan, check what's been done, and think about what's next rather than just charging ahead. Especially important for long plans with multiple phases.

## Session Management

32. **Start fresh chats for unrelated tasks** — context switching (profile API, then landing page design, then auth fix) degrades performance. By your third or fourth context switch, the model performs much worse than a brand new chat — even at the same total token count. So instead of doing profile API → design change → auth fix → research → profile page → scraper, you batch related tasks: profile API + profile page in one chat, auth fix in another, research + scraper in another.
33. **Group related tasks in the same session** — building a profile API route, then creating the profile page that uses it? That's related context — keep it in one chat. Small context switches (like fixing a typo you noticed on the landing page) are fine. But if it's a bigger task, start a new chat.
34. **Compact when on track; clear when confused** — ask yourself: am I still doing the same task? Is the model still progressing clearly — editing the right files, on track? Have I compacted recently? If yes to all, `/compact` is safe. If the model seems confused, is making insane edits, or you've compacted too much already, start a brand new chat instead.
35. **Write bug fix attempts to a file before starting new chat** — when a bug fix isn't working and you've been going in circles, tell Claude to write everything it tried so far into a brand new file. Start a fresh session, load that file first, and tell it to avoid repeating those attempts. This breaks the "repeat the same failed fix" loop. The file is also useful for other engineers on your team to understand what's been tried.
36. **Long context = repetition loops** — when the context window fills up, agents favor repeating past actions over synthesizing novel plans. Even if you tell it "don't do that again," it will. The history of all those failed attempts is right there in context, pulling the model back toward the same approaches. If you see the same fix attempted three times, it's time for a fresh chat.
37. **Turn off auto-compact for more control** — auto-compact can fire at bad times. For example, you're at 85% context, running a build command that takes a while — auto-compact fires mid-build, takes a few minutes, and loses context you cared about. Then when it does `git commit`, the commit message is bad because it lost the context of what it was doing. Turn it off with `/config`, then manually `/compact` or start fresh when you decide. Ideally don't do difficult problem solving past 50-60% of the context window.
38. **Use `/handoff` to pass state between sessions** — a custom slash command that writes everything Claude has done so far into a file. Start a fresh session, tag that file, and continue. Before loading it into the new session, edit the handoff file to strip out any bad decisions or dead ends — things that were "poisonous" to the previous context window. Only the relevant context carries over, so the new session is cleaner and more focused.
39. **The model knows when it's running out of context and will rush** — Claude is aware of its own context window. As it fills up, the model starts to panic and rush, giving incomplete solutions or cutting corners. If you see this happening — the model suddenly trying to do everything in one go instead of being methodical — write the plan to a file and continue in a fresh session before the quality degrades further.
40. **Use `/context` to audit your token usage** — run `/context` to see a visual breakdown of what's eating your context window. MCPs are a common offender — each tool call adds up fast, and you won't notice until you're wondering why Claude feels slow or confused. If you see one MCP dominating your usage, disable it for that directory or find a lighter alternative. Make this a habit: audit periodically, especially when costs spike or quality drops. You should also show your current context usage in the terminal statusline — configure it so you always know how much runway you have left without having to run a command.
41. **Use `/resume` and `/rename` to manage sessions** — if you accidentally kill a Claude instance or close the wrong terminal tab, `/resume` lets you recover the session and pick up where you left off instead of rebuilding all that context from scratch. Pair it with `/rename` to give your sessions descriptive names — like "profile-api" or "auth-refactor" — so when you need to resume, you're not guessing which session was which from a list of timestamps.

## Subagents, Skills & Hooks

42. **Use explore subagents to understand code before changing it** — don't modify code you haven't read. Let explore subagents scan first, then make informed changes. This is especially important as projects grow — Claude can get confused about which patterns to follow when there are multiple ways things are done across the codebase.
43. **Use multiple proposals for hard decisions** — have 2-3 subagents each generate a different approach, then pick the best one. Different approaches surface trade-offs you wouldn't see from a single proposal. Each subagent might find a different optimal path through the problem.
44. **Create custom slash commands for repeated prompts** — put them in `.claude/commands/` as markdown files. You can specify a cheaper model (Haiku for commits — committing doesn't need heavy reasoning), restrict allowed tools (only `git add`, `git status`, `git commit`), and use positional arguments (`$1`, `$2`) for flexible reuse. I have `/end-session` for committing, `/spec-developer` for planning, and `/start-session` for kicking off a new work block. Running a slash command is the same as pasting the prompt directly, but with model and tool settings baked in.
45. **Use `--agent` to test subagent behavior interactively** — `claude --agent Plan` gives you a full context window with planning capabilities. `claude --agent macOS-log-analyzer` runs your custom subagent directly so you can chat with it and see how it behaves. Normally subagents run autonomously and you can't intervene — this lets you experiment and fine-tune the prompt before deploying it. Also great for heavy planning sessions where you want the full context window dedicated to planning.
46. **Add logging so Claude can debug itself** — the reason agents are so good at coding is the tight feedback loop: make a change, run the code, see if it works, fix if not. For non-coding tasks, you lose that loop. Adding logging to your application gives Claude the same advantage — it can check logs, see what's actually happening, and fix issues based on real data instead of guessing.
47. **Use well-known packages** — tell Claude to use popular, well-documented libraries instead of obscure ones. The model has seen more examples of popular packages in training, so it writes better, more reliable code with them. Put this in your CLAUDE.md if you have preferred libraries.
48. **Mix models and modes within a workflow** — use Opus for hard reasoning and planning, switch to Sonnet or Haiku for simple edits, commits, and scripting. You can specify models per slash command so the switch is automatic — your `/end-session` command runs on Haiku because committing changes fast doesn't need Opus-level reasoning, while your main session stays on Opus for the complex work.

## Advanced & Niche

49. **Use headless mode for background workflows** — run Claude Code programmatically with `claude -p "your prompt"` and it returns just the final result, no interactive UI. Add `--output-format json` with a JSON schema and you get structured data back. You can define allowed tools, max turns, and model. The real power: build a Python script that runs Claude in headless mode hundreds of times in the background — batching receipt validation, data research, content generation. If you've already built skills and subagents for a workflow, they work in headless mode too. And you can parallelize — run five headless instances at once instead of one at a time.
50. **Use `/copy` to make it easier to share results** — good for drafting emails or messages. Copies Claude's last response to clipboard so you can paste it directly into Slack, email, or wherever you need it.
51. **Use `/export` to share full session transcripts** — export to clipboard or save to a file. Great for sharing a debugging session with a colleague on Slack, documenting what Claude did for the team, or keeping a record of how a tricky problem was solved.
52. **Use task list management for complex multi-step projects** — break work into tasks, assign to subagents, track progress. Essential when a feature touches many files across multiple steps. The task list gives structure to what would otherwise be a chaotic session.
53. **Use git to know exactly what Claude wrote** — after every session, `git diff` to review changes. The "you don't know what the AI wrote" criticism doesn't apply if you're using detailed plans with a spec developer — you know exactly what it's implementing because you collaborated on the plan and answered 20-30 questions about edge cases. The commit history with "Co-Authored-By: Claude" tags lets you audit which model wrote what code. This becomes especially important when cleaning up code from older models later.
54. **Use worktrees so parallel sessions don't interfere with your main project** — when you're running multiple Claude instances on the same codebase, they'll step on each other's changes. Git worktrees solve this — each Claude instance gets its own isolated copy of the repo on a separate branch. They can make edits, run builds, and test independently without conflicts. When the work is done, you merge the branch back in. Essential if you're doing the multi-instance parallel workflow — without worktrees, two instances editing the same file will corrupt each other's work.
55. **Use `/chrome` to automate browser tasks** — Claude can control a browser directly — navigate pages, click buttons, fill forms, take screenshots, and scrape data. Use it when you don't have API access to something but can get there via the web. It's composable with skills and commands: build a skill that opens Chrome, scrapes data from a dashboard, and brings it back into your session. Great for testing UI flows, grabbing data from admin panels, or automating repetitive browser work that doesn't have an API.
